# Semaine 11 — formation Simplon IA à Bordeaux, promo 1

Auteurs: Arnaud de Mouhy, Julien Tréguer et Louis Dorard — tous droits réservés

## Lundi 2/12 (Julien)

* Présentation veille CNN en 10'

## Mardi 3/12 (Louis)

* [Présentation veille log-loss](https://github.com/Simplon-IA-Bdx-1/log-loss-prez/blob/master/SujetVeille_LogLoss.ipynb) en 10'
* Suite house prices Keras / NN

## Mercredi 4/12 (Arnaud)

## Jeudi 5/12 (Louis)

* Présentation veilles en 2'
  * One-hot encoding pour transformer du catégoriel en binaire: avec Pandas (get_dummies) et scikit-learn (Vincent)
  * Créer une fonction sigmoïde en Python, et faire un plot (pour vérifier qu’elle est sigmoïde) (Guillaume)
  * Pourquoi features corrélées posent problème à la régression linéaire? (Julien)
  * Gradient Descent, Mini-batch GD, Stochastic GD: quelles différences? (Rachel)
  * 2 neurones entrée, 1 neurone sortie, 2 couches cachées de 3 neurones: combien de paramètres à apprendre? (coefficients et biais) (Laurent)
  * Avantages / désavantages d’initialiser tous les poids à 0? (Rodolphe)
  * Visualiser comportement de rescale, standardize, etc., sur jeux de données de votre choix (réel ou fictif) - par exemple, comment ça se passe avec les outliers? (sans vous limiter à ça non plus) (Damien)


## Vendredi 6/12 (Arnaud)

